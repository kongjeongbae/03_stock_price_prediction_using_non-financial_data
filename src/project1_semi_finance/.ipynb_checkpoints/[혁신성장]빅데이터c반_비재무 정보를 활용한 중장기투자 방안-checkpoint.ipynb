{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 재무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import time\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, scale\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "\n",
    "# # 데이터 불러오기 / 데이터 정리\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "IT_finance = pd.read_excel('./data/dongboo/IT_TOTAL_재무사항.xlsx')\n",
    "IT_validation_finance = pd.read_excel('./data/dongboo/IT_validation_재무사항.xlsx')\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# krx에서 가져온 자료\n",
    "IT_stock = pd.read_excel('./data/dongboo/IT_주가_total_krx.xlsx')\n",
    "IT_validation_stock = pd.read_excel('./data/dongboo/IT_validation_주가.xls')\n",
    "\n",
    "# IT_stock = pd.read_excel('./data/dongboo/IT_TOTAL_주가.xlsx')\n",
    "# Medicine_stock = pd.read_excel('./data/dongboo/제약_TOTAL_주가.xlsx')\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "IT = pd.merge(IT_finance,IT_stock,how = 'left', on = ['회사명','거래소코드','회계년도'])\n",
    "IT_validation = pd.merge(IT_validation_finance,IT_validation_stock,how = 'left', on = ['회사명','거래소코드','회계년도'])\n",
    "\n",
    "\n",
    "# # 회사별로 분리\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "lg = IT[IT['회사명'] == 'LG이노텍(주)']\n",
    "sdi = IT[IT['회사명'] == '삼성SDI(주)']\n",
    "ssem = IT[IT['회사명'] == '삼성전기(주)']\n",
    "hynix = IT[IT['회사명'] == '에스케이하이닉스(주)']\n",
    "\n",
    "# -----validation ---------\n",
    "\n",
    "samsungelectric = IT_validation[IT_validation['회사명'] == '삼성전자(주)']\n",
    "lgelectric = IT_validation[IT_validation['회사명'] == '엘지전자(주)']\n",
    "sds = IT_validation[IT_validation['회사명'] == '삼성에스디에스(주)']\n",
    "lgdisplay = IT_validation[IT_validation['회사명'] == '엘지디스플레이(주)']\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "def classify(stock):\n",
    "    \n",
    "    # 회계년도 순으로 정렬 및 인덱스 초기화\n",
    "    stock.sort_values('회계년도', ascending= True, inplace = True)\n",
    "    \n",
    "    stock.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    # 새로운 변수 추가\n",
    "    \n",
    "    stock['3개월후종가'] = stock['종가'][1:].reset_index(drop=True)\n",
    "    \n",
    "    stock['분기수익률'] = (stock['3개월후종가'] - stock['종가']) / stock['종가']\n",
    "    \n",
    "    stock['수익률상승하락'] = stock['분기수익률']\n",
    "    \n",
    "    for i in range(len(stock)):\n",
    "        if stock['분기수익률'][i] < 0.005:\n",
    "            stock['수익률상승하락'][i] = 0\n",
    "        else:\n",
    "            stock['수익률상승하락'][i] = 1\n",
    "        \n",
    "       \n",
    "    return stock\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "classify(lg)\n",
    "classify(sdi)\n",
    "classify(ssem)\n",
    "classify(hynix)\n",
    "\n",
    "# -----validation ---------\n",
    "\n",
    "classify(samsungelectric)\n",
    "classify(lgelectric)\n",
    "classify(sds)\n",
    "classify(lgdisplay)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# 3개월 후 오르는 지 안오르는 지 확인하는 모델이기에\n",
    "# 마지막 행은 올랐는지 확인할 수가 없음\n",
    "# 이에 마지막 행 제외시킴\n",
    "\n",
    "lg = lg.iloc[:-1,:]\n",
    "sdi = sdi.iloc[:-1,:]\n",
    "ssem = ssem.iloc[:-1,:]\n",
    "hynix = hynix.iloc[:-1,:]\n",
    "\n",
    "# -----validation ---------\n",
    "\n",
    "samsungelectric = samsungelectric.iloc[:-1,:]\n",
    "lgelectric = lgelectric.iloc[:-1,:]\n",
    "sds = sds.iloc[:-1,:]\n",
    "lgdisplay = lgdisplay.iloc[:-1,:]\n",
    "\n",
    "\n",
    "# # 산업별 변수 <3개월 후 종가>와의 상관관계 분석\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "lg_corr = lg.corr(method = 'pearson')\n",
    "df_lg = pd.DataFrame(lg_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_lg.columns = ['지표','3개월후종가']\n",
    "\n",
    "sdi_corr = sdi.corr(method = 'pearson')\n",
    "df_sdi = pd.DataFrame(sdi_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_sdi.columns = ['지표','3개월후종가']\n",
    "\n",
    "ssem_corr = ssem.corr(method = 'pearson')\n",
    "df_ssem = pd.DataFrame(ssem_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_ssem.columns = ['지표','3개월후종가']\n",
    "\n",
    "hynix_corr = hynix.corr(method = 'pearson')\n",
    "df_hynix = pd.DataFrame(hynix_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_hynix.columns = ['지표','3개월후종가']\n",
    "\n",
    "\n",
    "# # 산업별 상관관계 데이터프레임\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "pd.concat([df_lg.reset_index(drop = True), df_sdi.reset_index(drop = True), df_ssem.reset_index(drop = True), df_hynix.reset_index(drop = True)],axis = 1)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "list_corr = []\n",
    "order = 30 # 기업별로 상위 30개 상관관계 변수 추출\n",
    "\n",
    "for i in range(len(df_lg.index[:order])):\n",
    "    list_corr.append(df_lg.index[:order][i])\n",
    "    list_corr.append(df_sdi.index[:order][i])\n",
    "    list_corr.append(df_ssem.index[:order][i])\n",
    "    list_corr.append(df_hynix.index[:order][i])\n",
    "\n",
    "variable = pd.Series(list_corr).value_counts()\n",
    "variable = pd.DataFrame(variable).reset_index()\n",
    "variable.columns = ['var_index', 'number']\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "var = []\n",
    "for i in range(len(variable)):\n",
    "    var.append(df_lg[df_lg.index == variable['var_index'][i]]['지표'].values[0])\n",
    "var = pd.DataFrame(var)\n",
    "var.columns = ['var']\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "corr = pd.concat([variable,var], axis = 1)\n",
    "corr = corr[['var_index','var','number']]\n",
    "corr = corr[corr['var'] != '3개월후종가'].reset_index(drop = True)\n",
    "corr = corr[corr['var'] != '수익률상승하락'].reset_index(drop = True)\n",
    "corr = corr[corr['var'] != '분기수익률'].reset_index(drop = True)\n",
    "corr\n",
    "\n",
    "\n",
    "# # 위 자료를 보고 변수 선정\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "deep_lg = lg[corr['var'][0:20]]\n",
    "deep_sdi = sdi[corr['var'][0:20]]\n",
    "deep_ssem = ssem[corr['var'][0:20]]\n",
    "deep_hynix = hynix[corr['var'][0:20]]\n",
    "\n",
    "deep_lg['수익률상승하락'] = lg['수익률상승하락']\n",
    "deep_sdi['수익률상승하락'] = sdi['수익률상승하락']\n",
    "deep_ssem['수익률상승하락'] = ssem['수익률상승하락']\n",
    "deep_hynix['수익률상승하락'] = hynix['수익률상승하락']\n",
    "\n",
    "# ---------------- validtaion ----------------------\n",
    "\n",
    "deep_samsungelectric = samsungelectric[corr['var'][0:20]]\n",
    "deep_lgelectric = lgelectric[corr['var'][0:20]]\n",
    "deep_sds = sds[corr['var'][0:20]]\n",
    "deep_lgdisplay = lgdisplay[corr['var'][0:20]]\n",
    "\n",
    "deep_samsungelectric['수익률상승하락'] = samsungelectric['수익률상승하락']\n",
    "deep_lgelectric['수익률상승하락'] = lgelectric['수익률상승하락']\n",
    "deep_sds['수익률상승하락'] = sds['수익률상승하락']\n",
    "deep_lgdisplay['수익률상승하락'] = lgdisplay['수익률상승하락']\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "# 표준화\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_lg = StandardScaler()\n",
    "scale_lg = pd.DataFrame(scaler_lg.fit_transform(deep_lg.iloc[:,:-1]))\n",
    "\n",
    "scaler_sdi = StandardScaler()\n",
    "scale_sdi = pd.DataFrame(scaler_sdi.fit_transform(deep_sdi.iloc[:,:-1]))\n",
    "\n",
    "scaler_ssem = StandardScaler()\n",
    "scale_ssem = pd.DataFrame(scaler_ssem.fit_transform(deep_ssem.iloc[:,:-1]))\n",
    "\n",
    "scaler_hynix = StandardScaler()\n",
    "scale_hynix = pd.DataFrame(scaler_hynix.fit_transform(deep_hynix.iloc[:,:-1]))\n",
    "\n",
    "# --------------- validation ---------------------\n",
    "\n",
    "scaler_samsungelectric = StandardScaler()\n",
    "scale_samsungelectric = pd.DataFrame(scaler_samsungelectric.fit_transform(deep_samsungelectric.iloc[:,:-1]))\n",
    "\n",
    "scaler_lgelectric = StandardScaler()\n",
    "scale_lgelectric = pd.DataFrame(scaler_lgelectric.fit_transform(deep_lgelectric.iloc[:,:-1]))\n",
    "\n",
    "scaler_sds = StandardScaler()\n",
    "scale_sds = pd.DataFrame(scaler_sds.fit_transform(deep_sds.iloc[:,:-1]))\n",
    "\n",
    "scaler_lgdisplay = StandardScaler()\n",
    "scale_lgdisplay = pd.DataFrame(scaler_lgdisplay.fit_transform(deep_lgdisplay.iloc[:,:-1]))\n",
    "\n",
    "# 원래 값으로 변환\n",
    "# scaler_lg.inverse_transform(scale_lg)\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "# 주가를 합치려고 만듬(마지막 열을 가져오면 됨)\n",
    "deep_IT = pd.concat([deep_lg,deep_sdi,deep_ssem,deep_hynix], ignore_index=True)\n",
    "\n",
    "# 표준화한 변수를 합치려고 만듬\n",
    "scale_IT = pd.concat([scale_lg,scale_sdi,scale_ssem,scale_hynix], ignore_index=True)\n",
    "\n",
    "# --------------- validation ---------------------\n",
    "\n",
    "# 주가를 합치려고 만듬(마지막 열을 가져오면 됨)\n",
    "deep_IT_validation = pd.concat([deep_samsungelectric,deep_lgelectric,deep_sds,deep_lgdisplay], ignore_index=True)\n",
    "\n",
    "# 표준화한 변수를 합치려고 만듬\n",
    "scale_IT_validation = pd.concat([scale_samsungelectric,scale_lgelectric,scale_sds,scale_lgdisplay], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# # 상관관계 표 보기\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import font_manager, rc\n",
    "# import seaborn as sns\n",
    "# import matplotlib\n",
    "# font_location = \"c:/Windows/fonts/malgun.ttf\"\n",
    "# font_name = font_manager.FontProperties(fname=font_location).get_name()\n",
    "# matplotlib.rc('font', family=font_name)\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20,50))\n",
    "\n",
    "# sns.heatmap(data = deep_IT.corr(), annot = True)\n",
    "# # plt.savefig('tmp.png')\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    if uniform:\n",
    "        # 6 was used in the paper.\n",
    "        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        # 3 gives us approximately the same limints as above since this repicks\n",
    "        # values greater than 2 standard deviations from the mean.\n",
    "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "# 히든레이어 1개 짜리!!!!\n",
    "\n",
    "# Review : Learning rate and Evaluation\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "x_data = scale_IT\n",
    "y_data = deep_IT.iloc[:,[-1]]\n",
    "\n",
    "\n",
    "# parameters\n",
    "placeholder_num = len(x_data.columns)\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, placeholder_num])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[placeholder_num, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "# train = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "# Launch graph\n",
    "\n",
    "validation_number = 20\n",
    "\n",
    "graph_cost = []\n",
    "graph_acc = []\n",
    "\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = train_test_split(x_data, y_data, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in tqdm_notebook(range(50001)):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data_train, Y: y_data_train, keep_prob: 0.8})       \n",
    "        \n",
    "        h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data_test, Y: y_data_test, keep_prob: 1.0})\n",
    "        \n",
    "        graph_cost.append(cost_val)\n",
    "        graph_acc.append(a)\n",
    "        if step % 200 == 0 or step < 10 :\n",
    "            print(\"Step : {} \\t Cost : {} \\t Acc : {}\".format(step, cost_val, a*100))    \n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "print('모델 최고 정확도: ', max(graph_acc) * 100 , '%')\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "plt.rc('font', size=15)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=15)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=15)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=6)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=9)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=15)    # legend fontsize\n",
    "plt.rc('figure', titlesize=15)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.ylim([0,1.5])\n",
    "plt.plot(graph_cost, color = 'blue', label = 'model cost')\n",
    "plt.plot(graph_acc, color = 'red', label = 'Validation Acc')\n",
    "plt.title('model graph')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Cost & Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "pd.DataFrame({'graph_cost':graph_cost,'graph_acc': graph_acc})\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "# pd.DataFrame(y_data.iloc[-validation_number:,:].values, c.ravel()).reset_index()\n",
    "pd.DataFrame({'real':list(y_data_test.values.ravel()),'predict': list(c.ravel())})\n",
    "\n",
    "\n",
    "# # <span style=\"color:red\"> 비 가치주로 validation\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "# Launch graph\n",
    "\n",
    "validation_number = 20\n",
    "\n",
    "\n",
    "# samsungelectric / lgelectric / sds / lgdisplay\n",
    "\n",
    "# x_val_data = scale_lgdisplay\n",
    "# y_val_data = deep_lgdisplay.iloc[:,[-1]]\n",
    "\n",
    "\n",
    "graph_cost = []\n",
    "graph_acc = []\n",
    "\n",
    "x_val_data = scale_IT_validation\n",
    "y_val_data = deep_IT_validation.iloc[:,[-1]]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in tqdm_notebook(range(50001)):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data, keep_prob: 0.8})       \n",
    "        h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                               feed_dict={X: x_val_data, Y: y_val_data, keep_prob: 1.0})\n",
    "        \n",
    "        graph_cost.append(cost_val)\n",
    "        graph_acc.append(a)\n",
    "        if step % 200 == 0 or step < 10 :\n",
    "            print(\"Step : {} \\t Cost : {} \\t Acc : {}\".format(step, cost_val, a*100))\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "print('모델 최고 정확도: ', max(graph_acc) * 100 , '%')\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "pd.DataFrame({'graph_cost':graph_cost,'graph_acc': graph_acc})\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.ylim([0,1.5])\n",
    "plt.plot(graph_cost, color = 'blue', label = 'model cost')\n",
    "plt.plot(graph_acc, color = 'red', label = 'Validation Acc')\n",
    "plt.title('model graph')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Cost & Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "# print('모델 정확도: ', a * 100 , '%')\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "# pd.DataFrame(y_data.iloc[-validation_number:,:].values, c.ravel()).reset_index()\n",
    "pd.DataFrame({'real':list(y_val_data.values.ravel()),'predict': list(c.ravel())})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비재무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# import pandas as pd\n",
    "# import pandas_datareader.data as web\n",
    "# import time\n",
    "# import tensorflow\n",
    "# import matplotlib.pyplot as plt\n",
    "# import datetime as dt\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# import math\n",
    "# import os\n",
    "# from sklearn.preprocessing import MinMaxScaler, scale\n",
    "# from keras.utils import np_utils\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, Activation\n",
    "# from keras import optimizers\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from keras.models import load_model\n",
    "# from tqdm import tqdm_notebook\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "\n",
    "\n",
    "# # 데이터 불러오기 / 데이터 정리\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "IT_nonfinance = pd.read_excel('./data/dongboo/비재무/IT_비재무_TOTAL_최종.xlsx')\n",
    "IT_validation_nonfinance = pd.read_excel('./data/dongboo/비재무validation/validation_비재무_it_total_최종.xlsx')\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# \n",
    "IT_stock = pd.read_excel('./data/dongboo/IT_주가_total_krx.xlsx')\n",
    "\n",
    "IT_validation_stock = pd.read_excel('./data/dongboo/IT_validation_주가.xls')\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "IT = pd.merge(IT_nonfinance,IT_stock,how = 'left', on = ['회사명','거래소코드','회계년도'])\n",
    "\n",
    "IT_val = pd.merge(IT_validation_nonfinance,IT_validation_stock,how = 'left', on = ['회사명','거래소코드','회계년도'])\n",
    "\n",
    "\n",
    "# # 회사별로 분리\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "lg = IT[IT['회사명'] == 'LG이노텍(주)']\n",
    "sdi = IT[IT['회사명'] == '삼성SDI(주)']\n",
    "ssem = IT[IT['회사명'] == '삼성전기(주)']\n",
    "hynix = IT[IT['회사명'] == '에스케이하이닉스(주)']\n",
    "\n",
    "# ------------- validation ------------------\n",
    "\n",
    "samsungelectric = IT_val[IT_val['회사명'] == '삼성전자(주)']\n",
    "lgelectric = IT_val[IT_val['회사명'] == '엘지전자(주)']\n",
    "sds = IT_val[IT_val['회사명'] == '삼성에스디에스(주)']\n",
    "lgdisplay = IT_val[IT_val['회사명'] == '엘지디스플레이(주)']\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "def classify(stock):\n",
    "    \n",
    "    # 회계년도 순으로 정렬 및 인덱스 초기화\n",
    "    stock.sort_values('회계년도', ascending= True, inplace = True)\n",
    "    \n",
    "    stock.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    # 새로운 변수 추가\n",
    "    \n",
    "    stock['3개월후종가'] = stock['종가'][1:].reset_index(drop=True)\n",
    "    \n",
    "    stock['분기수익률'] = (stock['3개월후종가'] - stock['종가']) / stock['종가']\n",
    "    \n",
    "    stock['수익률상승하락'] = stock['분기수익률']\n",
    "    \n",
    "    for i in range(len(stock)):\n",
    "        if stock['분기수익률'][i] < 0.005:\n",
    "            stock['수익률상승하락'][i] = 0\n",
    "        else:\n",
    "            stock['수익률상승하락'][i] = 1\n",
    "        \n",
    "       \n",
    "    return stock\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "classify(lg)\n",
    "classify(sdi)\n",
    "classify(ssem)\n",
    "classify(hynix)\n",
    "\n",
    "# ------------- validation ------------------\n",
    "\n",
    "classify(samsungelectric)\n",
    "classify(lgelectric)\n",
    "classify(sds)\n",
    "classify(lgdisplay)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "lg = lg.iloc[:-1,:]\n",
    "sdi = sdi.iloc[:-1,:]\n",
    "ssem = ssem.iloc[:-1,:]\n",
    "hynix = hynix.iloc[:-1,:]\n",
    "\n",
    "# ------------- validation ------------------\n",
    "\n",
    "samsungelectric = samsungelectric.iloc[:-1,:]\n",
    "lgelectric = lgelectric.iloc[:-1,:]\n",
    "sds = sds.iloc[:-1,:]\n",
    "lgdisplay = lgdisplay.iloc[:-1,:]\n",
    "\n",
    "\n",
    "# # 산업별 변수 <3개월 후 종가>와의 상관관계 분석\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "# 밑에 함수로 해보기!!!!\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "lg_corr = lg.corr(method = 'pearson')\n",
    "df_lg = pd.DataFrame(lg_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_lg.columns = ['지표','3개월후종가']\n",
    "\n",
    "sdi_corr = sdi.corr(method = 'pearson')\n",
    "df_sdi = pd.DataFrame(sdi_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_sdi.columns = ['지표','3개월후종가']\n",
    "\n",
    "ssem_corr = ssem.corr(method = 'pearson')\n",
    "df_ssem = pd.DataFrame(ssem_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_ssem.columns = ['지표','3개월후종가']\n",
    "\n",
    "hynix_corr = hynix.corr(method = 'pearson')\n",
    "df_hynix = pd.DataFrame(hynix_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_hynix.columns = ['지표','3개월후종가']\n",
    "\n",
    "\n",
    "# # 산업별 상관관계 데이터프레임\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "pd.concat([df_lg.reset_index(drop = True), df_sdi.reset_index(drop = True), df_ssem.reset_index(drop = True), df_hynix.reset_index(drop = True)],axis = 1)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "list_corr = []\n",
    "order = 20 # 기업별로 상위 30개 상관관계 변수 추출\n",
    "\n",
    "for i in range(len(df_lg.index[:order])):\n",
    "    list_corr.append(df_lg.index[:order][i])\n",
    "    list_corr.append(df_sdi.index[:order][i])\n",
    "    list_corr.append(df_ssem.index[:order][i])\n",
    "    list_corr.append(df_hynix.index[:order][i])\n",
    "\n",
    "variable = pd.Series(list_corr).value_counts()\n",
    "variable = pd.DataFrame(variable).reset_index()\n",
    "variable.columns = ['var_index', 'number']\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "var = []\n",
    "for i in range(len(variable)):\n",
    "    var.append(df_lg[df_lg.index == variable['var_index'][i]]['지표'].values[0])\n",
    "var = pd.DataFrame(var)\n",
    "var.columns = ['var']\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "corr = pd.concat([variable,var], axis = 1)\n",
    "corr = corr[['var_index','var','number']]\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "corr = corr[corr['var'] != '3개월후종가'].reset_index(drop = True)\n",
    "corr = corr[corr['var'] != '수익률상승하락'].reset_index(drop = True)\n",
    "corr = corr[corr['var'] != '분기수익률'].reset_index(drop = True)\n",
    "corr\n",
    "\n",
    "\n",
    "# # 위 자료를 보고 변수 선정\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "deep_lg = lg[corr['var'][0:18]]\n",
    "deep_sdi = sdi[corr['var'][0:18]]\n",
    "deep_ssem = ssem[corr['var'][0:18]]\n",
    "deep_hynix = hynix[corr['var'][0:18]]\n",
    "\n",
    "deep_lg['수익률상승하락'] = lg['수익률상승하락']\n",
    "deep_sdi['수익률상승하락'] = sdi['수익률상승하락']\n",
    "deep_ssem['수익률상승하락'] = ssem['수익률상승하락']\n",
    "deep_hynix['수익률상승하락'] = hynix['수익률상승하락']\n",
    "\n",
    "# ------------ validation --------------\n",
    "\n",
    "deep_samsungelectric = samsungelectric[corr['var'][0:18]]\n",
    "deep_lgelectric = lgelectric[corr['var'][0:18]]\n",
    "deep_sds = sds[corr['var'][0:18]]\n",
    "deep_lgdisplay = lgdisplay[corr['var'][0:18]]\n",
    "\n",
    "deep_samsungelectric['수익률상승하락'] = samsungelectric['수익률상승하락']\n",
    "deep_lgelectric['수익률상승하락'] = lgelectric['수익률상승하락']\n",
    "deep_sds['수익률상승하락'] = sds['수익률상승하락']\n",
    "deep_lgdisplay['수익률상승하락'] = lgdisplay['수익률상승하락']\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "# 표준화\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_lg = StandardScaler()\n",
    "scale_lg = pd.DataFrame(scaler_lg.fit_transform(deep_lg.iloc[:,:-1]))\n",
    "\n",
    "scaler_sdi = StandardScaler()\n",
    "scale_sdi = pd.DataFrame(scaler_sdi.fit_transform(deep_sdi.iloc[:,:-1]))\n",
    "\n",
    "scaler_ssem = StandardScaler()\n",
    "scale_ssem = pd.DataFrame(scaler_ssem.fit_transform(deep_ssem.iloc[:,:-1]))\n",
    "\n",
    "scaler_hynix = StandardScaler()\n",
    "scale_hynix = pd.DataFrame(scaler_hynix.fit_transform(deep_hynix.iloc[:,:-1]))\n",
    "\n",
    "# ------------ validation --------------\n",
    "\n",
    "scaler_samsungelectric = StandardScaler()\n",
    "scale_samsungelectric = pd.DataFrame(scaler_lg.fit_transform(deep_samsungelectric.iloc[:,:-1]))\n",
    "\n",
    "scaler_lgelectric = StandardScaler()\n",
    "scale_lgelectric = pd.DataFrame(scaler_sdi.fit_transform(deep_lgelectric.iloc[:,:-1]))\n",
    "\n",
    "scaler_sds = StandardScaler()\n",
    "scale_sds = pd.DataFrame(scaler_ssem.fit_transform(deep_sds.iloc[:,:-1]))\n",
    "\n",
    "scaler_lgdisplay = StandardScaler()\n",
    "scale_lgdisplay = pd.DataFrame(scaler_hynix.fit_transform(deep_lgdisplay.iloc[:,:-1]))\n",
    "\n",
    "\n",
    "# 원래 값으로 변환\n",
    "# scaler_lg.inverse_transform(scale_lg)\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "# 주가를 합치려고 만듬(마지막 열을 가져오면 됨)\n",
    "deep_IT = pd.concat([deep_lg,deep_sdi,deep_ssem,deep_hynix], ignore_index=True)\n",
    "\n",
    "# 표준화한 변수를 합치려고 만듬\n",
    "scale_IT = pd.concat([scale_lg,scale_sdi,scale_ssem,scale_hynix], ignore_index=True)\n",
    "\n",
    "# ------------ validation --------------\n",
    "\n",
    "# 주가를 합치려고 만듬(마지막 열을 가져오면 됨)\n",
    "deep_IT_validation = pd.concat([deep_samsungelectric,deep_lgelectric,deep_sds,deep_lgdisplay], ignore_index=True)\n",
    "\n",
    "# 표준화한 변수를 합치려고 만듬\n",
    "scale_IT_validation = pd.concat([scale_samsungelectric,scale_lgelectric,scale_sds,scale_lgdisplay], ignore_index=True)\n",
    "\n",
    "\n",
    "# # 샤비어함수 및 히든레이어 5개\n",
    "\n",
    "# # 및 Validation\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    if uniform:\n",
    "        # 6 was used in the paper.\n",
    "        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        # 3 gives us approximately the same limints as above since this repicks\n",
    "        # values greater than 2 standard deviations from the mean.\n",
    "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "# 히든레이어 1개 짜리!!!!\n",
    "\n",
    "# Review : Learning rate and Evaluation\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "x_data = scale_IT\n",
    "y_data = deep_IT.iloc[:,[-1]]\n",
    "\n",
    "\n",
    "# parameters\n",
    "placeholder_num = len(x_data.columns)\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, placeholder_num])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[placeholder_num, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "# train = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # <span style=\"color:red\"> 가치주로 validation\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "# Launch graph\n",
    "\n",
    "validation_number = 20\n",
    "\n",
    "graph_cost = []\n",
    "graph_acc = []\n",
    "\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = train_test_split(x_data, y_data, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in tqdm_notebook(range(50001)):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data_train, Y: y_data_train, keep_prob: 0.8})       \n",
    "        h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data_test, Y: y_data_test, keep_prob: 1.0})\n",
    "        graph_cost.append(cost_val)\n",
    "        graph_acc.append(a)\n",
    "        if step % 200 == 0 or step < 10 :\n",
    "            print(\"Step : {} \\t Cost : {} \\t Acc : {}\".format(step, cost_val, a*100))    \n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "print('모델 최고 정확도: ', max(graph_acc) * 100 , '%')\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "plt.rc('font', size=15)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=15)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=15)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=6)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=9)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=15)    # legend fontsize\n",
    "plt.rc('figure', titlesize=15)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.ylim([0,1.5])\n",
    "plt.plot(graph_cost, color = 'blue', label = 'model cost')\n",
    "plt.plot(graph_acc, color = 'red', label = 'Validation Acc')\n",
    "plt.title('model graph')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Cost & Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "pd.DataFrame({'graph_cost':graph_cost,'graph_acc': graph_acc})\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "# pd.DataFrame(y_data.iloc[-validation_number:,:].values, c.ravel()).reset_index()\n",
    "pd.DataFrame({'real':list(y_data_test.values.ravel()),'predict': list(c.ravel())})\n",
    "\n",
    "\n",
    "# # <span style=\"color:red\"> 비 가치주로 validation\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "# Launch graph\n",
    "\n",
    "\n",
    "graph_cost = []\n",
    "graph_acc = []\n",
    "\n",
    "# samsungelectric / lgelectric / sds / lgdisplay\n",
    "\n",
    "# x_val_data = scale_lgdisplay\n",
    "# y_val_data = deep_lgdisplay.iloc[:,[-1]]\n",
    "\n",
    "x_val_data = scale_IT_validation\n",
    "y_val_data = deep_IT_validation.iloc[:,[-1]]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in tqdm_notebook(range(50001)):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data, keep_prob: 0.8})\n",
    "        h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                               feed_dict={X: x_val_data, Y: y_val_data, keep_prob: 1.0})\n",
    "        graph_cost.append(cost_val)\n",
    "        graph_acc.append(a)\n",
    "        if step % 200 == 0 or step < 10 :\n",
    "            \n",
    "            print(\"Step : {} \\t Cost : {} \\t Acc : {}\".format(step, cost_val, a*100))    \n",
    "\n",
    "    # Accuracy report\n",
    "   \n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "print('모델 최고 정확도: ', max(graph_acc) * 100 , '%')\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.ylim([0,1.5])\n",
    "plt.plot(graph_cost, color = 'blue', label = 'model cost')\n",
    "plt.plot(graph_acc, color = 'red', label = 'Validation Acc')\n",
    "plt.title('model graph')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Cost & Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "# pd.DataFrame(y_data.iloc[-validation_number:,:].values, c.ravel()).reset_index()\n",
    "pd.DataFrame({'real':list(y_val_data.iloc[:,:].values.ravel()),'predict': list(c.ravel())})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 재무+비재무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# import pandas as pd\n",
    "# import pandas_datareader.data as web\n",
    "# import time\n",
    "# import tensorflow\n",
    "# import matplotlib.pyplot as plt\n",
    "# import datetime as dt\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# import math\n",
    "# import os\n",
    "# from sklearn.preprocessing import MinMaxScaler, scale\n",
    "# from keras.utils import np_utils\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, Activation\n",
    "# from keras import optimizers\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from keras.models import load_model\n",
    "# from tqdm import tqdm_notebook\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "\n",
    "\n",
    "# # 데이터 불러오기 / 데이터 정리\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "IT_finance = pd.read_excel('./data/dongboo/IT_TOTAL_재무사항.xlsx')\n",
    "IT_nonfinance = pd.read_excel('./data/dongboo/비재무/IT_비재무_TOTAL_최종.xlsx')\n",
    "\n",
    "IT_validation_finance = pd.read_excel('./data/dongboo/IT_validation_재무사항.xlsx')\n",
    "IT_validation_nonfinance = pd.read_excel('./data/dongboo/비재무validation/validation_비재무_it_total_최종.xlsx')\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# krx에서 가져온 자료\n",
    "IT_stock = pd.read_excel('./data/dongboo/IT_주가_total_krx.xlsx')\n",
    "\n",
    "IT_validation_stock = pd.read_excel('./data/dongboo/IT_validation_주가.xls')\n",
    "\n",
    "# IT_stock = pd.read_excel('./data/dongboo/IT_TOTAL_주가.xlsx')\n",
    "# Medicine_stock = pd.read_excel('./data/dongboo/제약_TOTAL_주가.xlsx')\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "IT_info = pd.merge(IT_finance,IT_nonfinance, how = 'left', on = ['회사명','거래소코드','회계년도'])\n",
    "IT_val_info = pd.merge(IT_validation_finance,IT_validation_nonfinance, how = 'left', on = ['회사명','거래소코드','회계년도'])\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "IT = pd.merge(IT_info, IT_stock, how = 'left', on = ['회사명','거래소코드','회계년도'])\n",
    "IT_val = pd.merge(IT_val_info,IT_validation_stock,how = 'left', on = ['회사명','거래소코드','회계년도'])\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "IT_fi = pd.merge(IT_finance, IT_stock, how = 'left', on = ['회사명','거래소코드','회계년도'])\n",
    "IT_no_fi = pd.merge(IT_nonfinance, IT_stock, how = 'left', on = ['회사명','거래소코드','회계년도'])\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "lg = IT[IT['회사명'] == 'LG이노텍(주)']\n",
    "sdi = IT[IT['회사명'] == '삼성SDI(주)']\n",
    "ssem = IT[IT['회사명'] == '삼성전기(주)']\n",
    "hynix = IT[IT['회사명'] == '에스케이하이닉스(주)']\n",
    "\n",
    "# ------------- validation ------------------\n",
    "\n",
    "samsungelectric = IT_val[IT_val['회사명'] == '삼성전자(주)']\n",
    "lgelectric = IT_val[IT_val['회사명'] == '엘지전자(주)']\n",
    "sds = IT_val[IT_val['회사명'] == '삼성에스디에스(주)']\n",
    "lgdisplay = IT_val[IT_val['회사명'] == '엘지디스플레이(주)']\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "lg_f = IT_fi[IT_fi['회사명'] == 'LG이노텍(주)']\n",
    "sdi_f = IT_fi[IT_fi['회사명'] == '삼성SDI(주)']\n",
    "ssem_f = IT_fi[IT_fi['회사명'] == '삼성전기(주)']\n",
    "hynix_f = IT_fi[IT_fi['회사명'] == '에스케이하이닉스(주)']\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "lg_nf = IT_no_fi[IT_no_fi['회사명'] == 'LG이노텍(주)']\n",
    "sdi_nf = IT_no_fi[IT_no_fi['회사명'] == '삼성SDI(주)']\n",
    "ssem_nf = IT_no_fi[IT_no_fi['회사명'] == '삼성전기(주)']\n",
    "hynix_nf = IT_no_fi[IT_no_fi['회사명'] == '에스케이하이닉스(주)']\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def classify(stock):\n",
    "    \n",
    "    # 회계년도 순으로 정렬 및 인덱스 초기화\n",
    "    stock.sort_values('회계년도', ascending= True, inplace = True)\n",
    "    \n",
    "    stock.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    # 새로운 변수 추가\n",
    "    \n",
    "    stock['3개월후종가'] = stock['종가'][1:].reset_index(drop=True)\n",
    "    \n",
    "    stock['분기수익률'] = (stock['3개월후종가'] - stock['종가']) / stock['종가']\n",
    "    \n",
    "    stock['수익률상승하락'] = stock['분기수익률']\n",
    "    \n",
    "    for i in range(len(stock)):\n",
    "        if stock['분기수익률'][i] < 0.005:\n",
    "            stock['수익률상승하락'][i] = 0\n",
    "        else:\n",
    "            stock['수익률상승하락'][i] = 1\n",
    "        \n",
    "       \n",
    "    return stock\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "classify(lg)\n",
    "classify(sdi)\n",
    "classify(ssem)\n",
    "classify(hynix)\n",
    "\n",
    "classify(lg_f)\n",
    "classify(sdi_f)\n",
    "classify(ssem_f)\n",
    "classify(hynix_f)\n",
    "\n",
    "classify(lg_nf)\n",
    "classify(sdi_nf)\n",
    "classify(ssem_nf)\n",
    "classify(hynix_nf)\n",
    "\n",
    "# ------------- validation ------------------\n",
    "\n",
    "classify(samsungelectric)\n",
    "classify(lgelectric)\n",
    "classify(sds)\n",
    "classify(lgdisplay)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "lg = lg.iloc[:-1,:]\n",
    "sdi = sdi.iloc[:-1,:]\n",
    "ssem = ssem.iloc[:-1,:]\n",
    "hynix = hynix.iloc[:-1,:]\n",
    "\n",
    "lg_f = lg_f.iloc[:-1,:]\n",
    "sdi_f = sdi_f.iloc[:-1,:]\n",
    "ssem_f = ssem_f.iloc[:-1,:]\n",
    "hynix_f = hynix_f.iloc[:-1,:]\n",
    "\n",
    "lg_nf = lg_nf.iloc[:-1,:]\n",
    "sdi_nf = sdi_nf.iloc[:-1,:]\n",
    "ssem_nf = ssem_nf.iloc[:-1,:]\n",
    "hynix_nf = hynix_nf.iloc[:-1,:]\n",
    "\n",
    "# ------------- validation ------------------\n",
    "\n",
    "samsungelectric = samsungelectric.iloc[:-1,:]\n",
    "lgelectric = lgelectric.iloc[:-1,:]\n",
    "sds = sds.iloc[:-1,:]\n",
    "lgdisplay = lgdisplay.iloc[:-1,:]\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "lg_f_corr = lg_f.corr(method = 'pearson')\n",
    "df_lg_f = pd.DataFrame(lg_f_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_lg_f.columns = ['지표','3개월후종가']\n",
    "\n",
    "sdi_f_corr = sdi_f.corr(method = 'pearson')\n",
    "df_sdi_f = pd.DataFrame(sdi_f_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_sdi_f.columns = ['지표','3개월후종가']\n",
    "\n",
    "ssem_f_corr = ssem_f.corr(method = 'pearson')\n",
    "df_ssem_f = pd.DataFrame(ssem_f_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_ssem_f.columns = ['지표','3개월후종가']\n",
    "\n",
    "hynix_f_corr = hynix_f.corr(method = 'pearson')\n",
    "df_hynix_f = pd.DataFrame(hynix_f_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_hynix_f.columns = ['지표','3개월후종가']\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "lg_nf_corr = lg_nf.corr(method = 'pearson')\n",
    "df_lg_nf = pd.DataFrame(lg_nf_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_lg_nf.columns = ['지표','3개월후종가']\n",
    "\n",
    "sdi_nf_corr = sdi_nf.corr(method = 'pearson')\n",
    "df_sdi_nf = pd.DataFrame(sdi_nf_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_sdi_nf.columns = ['지표','3개월후종가']\n",
    "\n",
    "ssem_nf_corr = ssem_nf.corr(method = 'pearson')\n",
    "df_ssem_nf = pd.DataFrame(ssem_nf_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_ssem_nf.columns = ['지표','3개월후종가']\n",
    "\n",
    "hynix_nf_corr = hynix_nf.corr(method = 'pearson')\n",
    "df_hynix_nf = pd.DataFrame(hynix_nf_corr['3개월후종가']).reset_index().sort_values('3개월후종가', ascending = False)\n",
    "df_hynix_nf.columns = ['지표','3개월후종가']\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "list_corr = []\n",
    "order = 30 # 기업별로 상위 30개 상관관계 변수 추출\n",
    "\n",
    "for i in range(len(df_lg_f.index[:order])):\n",
    "    list_corr.append(df_lg_f.index[:order][i])\n",
    "    list_corr.append(df_sdi_f.index[:order][i])\n",
    "    list_corr.append(df_ssem_f.index[:order][i])\n",
    "    list_corr.append(df_hynix_f.index[:order][i])\n",
    "\n",
    "variable = pd.Series(list_corr).value_counts()\n",
    "variable = pd.DataFrame(variable).reset_index()\n",
    "variable.columns = ['var_index', 'number']\n",
    "\n",
    "var = []\n",
    "\n",
    "for i in range(len(variable)):\n",
    "    var.append(df_lg_f[df_lg_f.index == variable['var_index'][i]]['지표'].values[0])\n",
    "var = pd.DataFrame(var)\n",
    "var.columns = ['var']\n",
    "\n",
    "corr = pd.concat([variable,var], axis = 1)\n",
    "corr = corr[['var_index','var','number']]\n",
    "\n",
    "corr = corr[corr['var'] != '3개월후종가'].reset_index(drop = True)\n",
    "corr = corr[corr['var'] != '수익률상승하락'].reset_index(drop = True)\n",
    "corr = corr[corr['var'] != '분기수익률'].reset_index(drop = True)\n",
    "corr\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "list_corr_nf = []\n",
    "order = 15 # 기업별로 상위 30개 상관관계 변수 추출\n",
    "\n",
    "for i in range(len(df_lg_nf.index[:order])):\n",
    "    list_corr_nf.append(df_lg_nf.index[:order][i])\n",
    "    list_corr_nf.append(df_sdi_nf.index[:order][i])\n",
    "    list_corr_nf.append(df_ssem_nf.index[:order][i])\n",
    "    list_corr_nf.append(df_hynix_nf.index[:order][i])\n",
    "\n",
    "variable_nf = pd.Series(list_corr_nf).value_counts()\n",
    "variable_nf = pd.DataFrame(variable_nf).reset_index()\n",
    "variable_nf.columns = ['var_index', 'number']\n",
    "\n",
    "var_nf = []\n",
    "\n",
    "\n",
    "for i in range(len(variable_nf)):\n",
    "    var_nf.append(df_lg_nf[df_lg_nf.index == variable_nf['var_index'][i]]['지표'].values[0])\n",
    "var_nf = pd.DataFrame(var_nf)\n",
    "var_nf.columns = ['var']\n",
    "\n",
    "corr_nf = pd.concat([variable_nf,var_nf], axis = 1)\n",
    "corr_nf = corr_nf[['var_index','var','number']]\n",
    "\n",
    "corr_nf = corr_nf[corr_nf['var'] != '3개월후종가'].reset_index(drop = True)\n",
    "corr_nf = corr_nf[corr_nf['var'] != '수익률상승하락'].reset_index(drop = True)\n",
    "corr_nf = corr_nf[corr_nf['var'] != '분기수익률'].reset_index(drop = True)\n",
    "\n",
    "\n",
    "corr_nf = corr_nf[corr_nf['var'] != '거래대금'].reset_index(drop = True)\n",
    "corr_nf = corr_nf[corr_nf['var'] != '종가'].reset_index(drop = True)\n",
    "corr_nf = corr_nf[corr_nf['var'] != '최저가'].reset_index(drop = True)\n",
    "corr_nf = corr_nf[corr_nf['var'] != '최고가'].reset_index(drop = True)\n",
    "corr_nf = corr_nf[corr_nf['var'] != '거래량'].reset_index(drop = True)\n",
    "corr_nf\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "corr = pd.concat([corr[:10],corr_nf[:10]],axis = 0).reset_index(drop = True)\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "deep_lg = lg[corr['var'][:20]]\n",
    "deep_sdi = sdi[corr['var'][:20]]\n",
    "deep_ssem = ssem[corr['var'][:20]]\n",
    "deep_hynix = hynix[corr['var'][:20]]\n",
    "\n",
    "deep_lg['수익률상승하락'] = lg['수익률상승하락']\n",
    "deep_sdi['수익률상승하락'] = sdi['수익률상승하락']\n",
    "deep_ssem['수익률상승하락'] = ssem['수익률상승하락']\n",
    "deep_hynix['수익률상승하락'] = hynix['수익률상승하락']\n",
    "\n",
    "deep_lg = deep_lg.dropna(axis = 0)\n",
    "deep_ssem = deep_ssem.dropna(axis = 0)\n",
    "deep_sdi = deep_sdi.dropna(axis = 0)\n",
    "deep_hynix = deep_hynix.dropna(axis = 0)\n",
    "# ------------ validation --------------\n",
    "\n",
    "deep_samsungelectric = samsungelectric[corr['var'][0:20]]\n",
    "deep_lgelectric = lgelectric[corr['var'][0:20]]\n",
    "deep_sds = sds[corr['var'][0:20]]\n",
    "deep_lgdisplay = lgdisplay[corr['var'][0:20]]\n",
    "\n",
    "deep_samsungelectric['수익률상승하락'] = samsungelectric['수익률상승하락']\n",
    "deep_lgelectric['수익률상승하락'] = lgelectric['수익률상승하락']\n",
    "deep_sds['수익률상승하락'] = sds['수익률상승하락']\n",
    "deep_lgdisplay['수익률상승하락'] = lgdisplay['수익률상승하락']\n",
    "\n",
    "deep_samsungelectric = deep_samsungelectric.dropna(axis = 0)\n",
    "deep_lgelectric = deep_lgelectric.dropna(axis = 0)\n",
    "deep_sds = deep_sds.dropna(axis = 0)\n",
    "deep_lgdisplay = deep_lgdisplay.dropna(axis = 0)\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "# 표준화\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_lg = StandardScaler()\n",
    "scale_lg = pd.DataFrame(scaler_lg.fit_transform(deep_lg.iloc[:,:-1]))\n",
    "\n",
    "scaler_sdi = StandardScaler()\n",
    "scale_sdi = pd.DataFrame(scaler_sdi.fit_transform(deep_sdi.iloc[:,:-1]))\n",
    "\n",
    "scaler_ssem = StandardScaler()\n",
    "scale_ssem = pd.DataFrame(scaler_ssem.fit_transform(deep_ssem.iloc[:,:-1]))\n",
    "\n",
    "scaler_hynix = StandardScaler()\n",
    "scale_hynix = pd.DataFrame(scaler_hynix.fit_transform(deep_hynix.iloc[:,:-1]))\n",
    "\n",
    "# ------------ validation --------------\n",
    "\n",
    "scaler_samsungelectric = StandardScaler()\n",
    "scale_samsungelectric = pd.DataFrame(scaler_lg.fit_transform(deep_samsungelectric.iloc[:,:-1]))\n",
    "\n",
    "scaler_lgelectric = StandardScaler()\n",
    "scale_lgelectric = pd.DataFrame(scaler_sdi.fit_transform(deep_lgelectric.iloc[:,:-1]))\n",
    "\n",
    "scaler_sds = StandardScaler()\n",
    "scale_sds = pd.DataFrame(scaler_ssem.fit_transform(deep_sds.iloc[:,:-1]))\n",
    "\n",
    "scaler_lgdisplay = StandardScaler()\n",
    "scale_lgdisplay = pd.DataFrame(scaler_hynix.fit_transform(deep_lgdisplay.iloc[:,:-1]))\n",
    "\n",
    "# 원래 값으로 변환\n",
    "# scaler_lg.inverse_transform(scale_lg)\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "# 주가를 합치려고 만듬(마지막 열을 가져오면 됨)\n",
    "deep_IT = pd.concat([deep_lg,deep_sdi,deep_ssem,deep_hynix], ignore_index=True)\n",
    "\n",
    "# 표준화한 변수를 합치려고 만듬\n",
    "scale_IT = pd.concat([scale_lg,scale_sdi,scale_ssem,scale_hynix], ignore_index=True)\n",
    "\n",
    "# ------------ validation --------------\n",
    "\n",
    "# 주가를 합치려고 만듬(마지막 열을 가져오면 됨)\n",
    "deep_IT_validation = pd.concat([deep_samsungelectric,deep_lgelectric,deep_sds,deep_lgdisplay], ignore_index=True)\n",
    "\n",
    "# 표준화한 변수를 합치려고 만듬\n",
    "scale_IT_validation = pd.concat([scale_samsungelectric,scale_lgelectric,scale_sds,scale_lgdisplay], ignore_index=True)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import font_manager, rc\n",
    "# import seaborn as sns\n",
    "# import matplotlib\n",
    "# font_location = \"c:/Windows/fonts/malgun.ttf\"\n",
    "# font_name = font_manager.FontProperties(fname=font_location).get_name()\n",
    "# matplotlib.rc('font', family=font_name)\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20,50))\n",
    "\n",
    "# sns.heatmap(data = scale_IT.corr(), annot = True)\n",
    "# # plt.savefig('tmp.png')\n",
    "\n",
    "\n",
    "# # 샤비어함수 및 히든레이어 5개\n",
    "\n",
    "# # 및 Validation\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    if uniform:\n",
    "        # 6 was used in the paper.\n",
    "        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        # 3 gives us approximately the same limints as above since this repicks\n",
    "        # values greater than 2 standard deviations from the mean.\n",
    "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "# 히든레이어 1개 짜리!!!!\n",
    "\n",
    "# Review : Learning rate and Evaluation\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "tf.reset_default_graph()\n",
    "\n",
    "deep_IT = pd.concat([deep_hynix,deep_ssem,deep_sdi,deep_lg], ignore_index=True)\n",
    "scale_IT = pd.concat([scale_hynix,scale_ssem,scale_sdi,scale_lg], ignore_index=True)\n",
    "\n",
    "x_data = scale_IT\n",
    "y_data = deep_IT.iloc[:,[-1]]\n",
    "\n",
    "\n",
    "graph_cost = []\n",
    "graph_acc = []\n",
    "\n",
    "# parameters\n",
    "placeholder_num = len(x_data.columns)\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, placeholder_num])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[placeholder_num, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "# train = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # <span style=\"color:red\"> 가치주로 validation\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "# Launch graph\n",
    "\n",
    "# validation_number = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = train_test_split(x_data, y_data, test_size=0.2, random_state=0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in tqdm_notebook(range(50001)):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data_train, Y: y_data_train, keep_prob: 1.0})       \n",
    "        if step % 200 == 0 or step < 10 :\n",
    "            h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data_test, Y: y_data_test, keep_prob: 1.0})\n",
    "            graph_cost.append(cost_val)\n",
    "            graph_acc.append(a)\n",
    "            print(\"Step : {} \\t Cost : {} \\t Acc : {}\".format(step, cost_val, a*100))    \n",
    "\n",
    "#     for step in tqdm_notebook(range(9001)):\n",
    "#         cost_val, _ = sess.run([cost, train], feed_dict={X: x_data.iloc[:-validation_number,:], Y: y_data.iloc[:-validation_number,:], keep_prob: 1.0})       \n",
    "#         if step % 200 == 0 or step < 10 :\n",
    "#             h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "#                        feed_dict={X: x_data.iloc[-validation_number:,:], Y: y_data.iloc[-validation_number:,:], keep_prob: 1.0})\n",
    "#             graph_cost.append(cost_val)\n",
    "#             graph_acc.append(a)\n",
    "#             print(\"Step : {} \\t Cost : {} \\t Acc : {}\".format(step, cost_val, a*100))    \n",
    "\n",
    "    # Accuracy report\n",
    "#     h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "#                        feed_dict={X: x_data.iloc[-validation_number:,:], Y: y_data.iloc[-validation_number:,:], keep_prob: 1.0})\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "print('모델 최고 정확도: ', max(graph_acc) * 100 , '%')\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "pd.DataFrame({'real':list(y_data_test.values.ravel()),'predict': list(c.ravel())})\n",
    "\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "plt.rc('font', size=15)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=15)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=15)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=6)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=9)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=15)    # legend fontsize\n",
    "plt.rc('figure', titlesize=15)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.ylim([0,1.5])\n",
    "plt.plot(graph_cost, color = 'blue', label = 'model cost')\n",
    "plt.plot(graph_acc, color = 'red', label = 'Validation Acc')\n",
    "plt.title('model graph')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Cost & Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # <span style=\"color:red\"> 비 가치주로 validation\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "# x_val_data = scale_sds\n",
    "# y_val_data = deep_sds.iloc[:,[-1]]\n",
    "x_val_data = scale_IT_validation\n",
    "y_val_data = deep_IT_validation.iloc[:,[-1]]\n",
    "\n",
    "# samsungelectric\n",
    "# lgelectric\n",
    "# sds\n",
    "# lgdisplay\n",
    "\n",
    "graph_cost = []\n",
    "graph_acc = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in tqdm_notebook(range(50001)):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data, keep_prob: 1.0})       \n",
    "        if step % 200 == 0 or step < 10 :\n",
    "            h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                               feed_dict={X: x_val_data.iloc[:,:], Y: y_val_data.iloc[:,:], keep_prob: 1.0})\n",
    "            graph_cost.append(cost_val)\n",
    "            graph_acc.append(a)\n",
    "            print(\"Step : {} \\t Cost : {} \\t Acc : {}\".format(step, cost_val, a*100))    \n",
    "  \n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "print('모델 최고 정확도: ', max(graph_acc) * 100 , '%')\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.ylim([0,1.5])\n",
    "plt.plot(graph_cost, color = 'blue', label = 'model cost')\n",
    "plt.plot(graph_acc, color = 'red', label = 'Validation Acc')\n",
    "plt.title('model graph')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Cost & Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "pd.DataFrame({'real':list(y_val_data.values.ravel()),'predict': list(c.ravel())})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
